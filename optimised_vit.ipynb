{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffb4b1f-856d-44d6-bbdb-ebcd54243b99",
   "metadata": {},
   "source": [
    "# install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff008bb-70d8-46fb-bb5e-150f773e4909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:03:11.684082Z",
     "iopub.status.busy": "2023-12-12T18:03:11.683305Z",
     "iopub.status.idle": "2023-12-12T18:03:15.097973Z",
     "shell.execute_reply": "2023-12-12T18:03:15.096843Z",
     "shell.execute_reply.started": "2023-12-12T18:03:11.684052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.12.1+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.13.1+cu116)\n",
      "Collecting timm\n",
      "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (5.4.1)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm) (0.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
      "Installing collected packages: safetensors, timm\n",
      "Successfully installed safetensors-0.4.1 timm-0.9.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision timm pandas requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5d26d-a505-4227-8484-82588f53064c",
   "metadata": {},
   "source": [
    "## The below code uses a pre-trained DeiT model for image classification and prints the output that is the index of the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c821335-f8f0-4706-b301-59db29bfa076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:04:28.685856Z",
     "iopub.status.busy": "2023-12-12T18:04:28.685557Z",
     "iopub.status.idle": "2023-12-12T18:04:36.304025Z",
     "shell.execute_reply": "2023-12-12T18:04:36.303154Z",
     "shell.execute_reply.started": "2023-12-12T18:04:28.685831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
      "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696cbacc34944912a15286071f5c82c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import timm\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "print(torch.__version__)\n",
    "# should be 1.8.0\n",
    "\n",
    "\n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=3),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "])\n",
    "\n",
    "img = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\n",
    "img = transform(img)[None,]\n",
    "out = model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd173eff-4872-4c37-9fe2-82c90013594d",
   "metadata": {},
   "source": [
    "# Scripting DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a38597b-2e46-4fb5-b182-8b29cf4fcc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:04:58.577579Z",
     "iopub.status.busy": "2023-12-12T18:04:58.577031Z",
     "iopub.status.idle": "2023-12-12T18:05:00.478390Z",
     "shell.execute_reply": "2023-12-12T18:05:00.477674Z",
     "shell.execute_reply.started": "2023-12-12T18:04:58.577552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "#load the model \n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"fbdeit_scripted.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f1f9e-9715-4512-8755-3bdff8581f32",
   "metadata": {},
   "source": [
    "# Quantizing DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e398e40-922d-44de-9bc1-ef3a703b8f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:03.265078Z",
     "iopub.status.busy": "2023-12-12T18:05:03.264475Z",
     "iopub.status.idle": "2023-12-12T18:05:05.351639Z",
     "shell.execute_reply": "2023-12-12T18:05:05.350826Z",
     "shell.execute_reply.started": "2023-12-12T18:05:03.265053Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W TensorImpl.h:1405] Warning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (function operator())\n"
     ]
    }
   ],
   "source": [
    "# Use 'x86' for server inference (the old 'fbgemm' is still available but 'x86' is the recommended default) and ``qnnpack`` for mobile inference.\n",
    "backend = \"qnnpack\" # replaced with ``qnnpack`` causing much worse inference speed for quantized model on this notebook\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n",
    "scripted_quantized_model = torch.jit.script(quantized_model)\n",
    "scripted_quantized_model.save(\"fbdeit_scripted_quantized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86797ed3-f5c3-4164-a07a-0144978dfc5d",
   "metadata": {},
   "source": [
    "Use the scripted_quantized_model to generate the same inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1fb1a14-a272-46a7-9c4a-417e8657d5d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:08.523083Z",
     "iopub.status.busy": "2023-12-12T18:05:08.522488Z",
     "iopub.status.idle": "2023-12-12T18:05:10.712996Z",
     "shell.execute_reply": "2023-12-12T18:05:10.712372Z",
     "shell.execute_reply.started": "2023-12-12T18:05:08.523060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "out = scripted_quantized_model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())\n",
    "# The same output 269 should be printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bfb43-4741-4725-8f04-33ee1093fd9e",
   "metadata": {},
   "source": [
    "# Optimizing DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031b8dc8-b5e2-46a2-a158-2ed395e86703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:14.627561Z",
     "iopub.status.busy": "2023-12-12T18:05:14.626658Z",
     "iopub.status.idle": "2023-12-12T18:05:15.216921Z",
     "shell.execute_reply": "2023-12-12T18:05:15.216338Z",
     "shell.execute_reply.started": "2023-12-12T18:05:14.627533Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "optimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\n",
    "optimized_scripted_quantized_model.save(\"fbdeit_optimized_scripted_quantized.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f575e75f-1a44-4dc3-b84e-cfecb06b0022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:18.978942Z",
     "iopub.status.busy": "2023-12-12T18:05:18.977843Z",
     "iopub.status.idle": "2023-12-12T18:05:22.387089Z",
     "shell.execute_reply": "2023-12-12T18:05:22.386409Z",
     "shell.execute_reply.started": "2023-12-12T18:05:18.978908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "out = optimized_scripted_quantized_model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())\n",
    "# Again, the same output 269 should be printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf22fb-25fd-4947-8fcd-bdd88e385a8c",
   "metadata": {},
   "source": [
    "# Using Lite Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99455852-b93a-447a-82a3-be3eca146537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:25.549701Z",
     "iopub.status.busy": "2023-12-12T18:05:25.549275Z",
     "iopub.status.idle": "2023-12-12T18:05:25.677496Z",
     "shell.execute_reply": "2023-12-12T18:05:25.676857Z",
     "shell.execute_reply.started": "2023-12-12T18:05:25.549664Z"
    }
   },
   "outputs": [],
   "source": [
    "optimized_scripted_quantized_model._save_for_lite_interpreter(\"fbdeit_optimized_scripted_quantized_lite.ptl\")\n",
    "ptl = torch.jit.load(\"fbdeit_optimized_scripted_quantized_lite.ptl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f08fe-ce45-44dc-a72e-b4d6c3d30309",
   "metadata": {},
   "source": [
    "# Comparing Inference Speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a97769-ec15-458c-a817-ea86d2b22fca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:29.771737Z",
     "iopub.status.busy": "2023-12-12T18:05:29.771476Z",
     "iopub.status.idle": "2023-12-12T18:05:37.033153Z",
     "shell.execute_reply": "2023-12-12T18:05:37.032464Z",
     "shell.execute_reply.started": "2023-12-12T18:05:29.771717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model: 794.15ms\n",
      "scripted model: 1474.18ms\n",
      "scripted & quantized model: 1105.06ms\n",
      "scripted & quantized & optimized model: 841.92ms\n",
      "lite model: 1769.51ms\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n",
    "    out = model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof2:\n",
    "    out = scripted_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof3:\n",
    "    out = scripted_quantized_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof4:\n",
    "    out = optimized_scripted_quantized_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof5:\n",
    "    out = ptl(img)\n",
    "\n",
    "print(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\n",
    "print(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\n",
    "print(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\n",
    "print(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\n",
    "print(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45707943-04cc-4d2a-8b89-61f8094328ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:05:42.721064Z",
     "iopub.status.busy": "2023-12-12T18:05:42.720053Z",
     "iopub.status.idle": "2023-12-12T18:05:43.653094Z",
     "shell.execute_reply": "2023-12-12T18:05:43.652662Z",
     "shell.execute_reply.started": "2023-12-12T18:05:42.721021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model Inference Time Reduction\n",
      "0                          original model       794.15ms        0%\n",
      "1                          scripted model      1474.18ms   -85.63%\n",
      "2              scripted & quantized model      1105.06ms   -39.15%\n",
      "3  scripted & quantized & optimized model       841.92ms    -6.01%\n",
      "4                              lite model      1769.51ms  -122.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n        Model                             Inference Time    Reduction\\n0   original model                             1236.69ms           0%\\n1   scripted model                             1226.72ms        0.81%\\n2   scripted & quantized model                  593.19ms       52.03%\\n3   scripted & quantized & optimized model      598.01ms       51.64%\\n4   lite model                                  600.72ms       51.43%\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'Model': ['original model','scripted model', 'scripted & quantized model', 'scripted & quantized & optimized model', 'lite model']})\n",
    "df = pd.concat([df, pd.DataFrame([\n",
    "    [\"{:.2f}ms\".format(prof1.self_cpu_time_total/1000), \"0%\"],\n",
    "    [\"{:.2f}ms\".format(prof2.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof2.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
    "    [\"{:.2f}ms\".format(prof3.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof3.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
    "    [\"{:.2f}ms\".format(prof4.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof4.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
    "    [\"{:.2f}ms\".format(prof5.self_cpu_time_total/1000),\n",
    "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof5.self_cpu_time_total)/prof1.self_cpu_time_total*100)]],\n",
    "    columns=['Inference Time', 'Reduction'])], axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\"\"\"\n",
    "        Model                             Inference Time    Reduction\n",
    "0   original model                             1236.69ms           0%\n",
    "1   scripted model                             1226.72ms        0.81%\n",
    "2   scripted & quantized model                  593.19ms       52.03%\n",
    "3   scripted & quantized & optimized model      598.01ms       51.64%\n",
    "4   lite model                                  600.72ms       51.43%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "766c9c7d-1288-439d-8204-bd73fc25348f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T10:42:52.086274Z",
     "iopub.status.busy": "2023-12-07T10:42:52.085961Z",
     "iopub.status.idle": "2023-12-07T10:42:52.700746Z",
     "shell.execute_reply": "2023-12-07T10:42:52.700131Z",
     "shell.execute_reply.started": "2023-12-07T10:42:52.086254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    }
   ],
   "source": [
    "#test code\n",
    "img = Image.open(requests.get(\"https://images.rawpixel.com/image_png_800/czNmcy1wcml2YXRlL3Jhd3BpeGVsX2ltYWdlcy93ZWJzaXRlX2NvbnRlbnQvcHUyMzMxNjM2LWltYWdlLTAxLXJtNTAzXzMtbDBqOXFrNnEucG5n.png\", stream=True).raw)\n",
    "img = transform(img)[None,]\n",
    "out = model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
